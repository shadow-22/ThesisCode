{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba796e9-050d-4fba-af51-ddc55b5907bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from glob import glob\n",
    "import nfstream\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import os.path\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e86e246-1af1-4516-9668-f86ec61771d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Destination Port', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
    "                     'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "                     'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', \n",
    "                     'Bwd Packet Length Std', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "                     'Flow IAT Min', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
    "                     'Bwd IAT Max', 'Bwd IAT Min', 'Min Packet Length', 'Max Packet Length', \n",
    "                     'Packet Length Mean', 'Packet Length Std', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', \n",
    "                     'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count']\n",
    "\n",
    "added_features = ['Fwd PSH Flags', 'Fwd URG Flags', 'Bwd PSH Flags', 'Bwd URG Flags']\n",
    "\n",
    "#extra_features = ['Active Max', 'Idle Max' ]\n",
    "\n",
    "computed_features = ['Flow Duration', 'Flow Bytes/s', 'Flow Packets/s', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Variance']\n",
    "\n",
    "selected_features_total = (selected_features + \n",
    "                           added_features + \n",
    "                           computed_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c427b24-8e74-46bf-995b-0303ea8085fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    SimpleImputer(), StandardScaler(), MLPClassifier(max_iter=1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2580a8c2-1f42-41df-be92-7b1f8c4b7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsa\\AppData\\Local\\Temp\\ipykernel_16772\\4155168708.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = 'C:/Users/katsa/OneDrive/Jupyter_files/shallow_models_online/cic_train_sample_binary.csv'\n",
    "CICDataset_train = pd.read_csv(train_dataset_path)\n",
    "X_train, y_train = CICDataset_train[selected_features_total], CICDataset_train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fec40e-9258-41c2-8913-629b8cf9c0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsa\\AppData\\Local\\Temp\\ipykernel_16772\\3637019026.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = 'C:/Users/katsa/OneDrive/Jupyter_files/shallow_models_online/cic_test_sample_binary.csv'\n",
    "CICDataset_test = pd.read_csv(test_dataset_path)\n",
    "X_test, y_test = CICDataset_test[selected_features_total], CICDataset_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2843f02-32f2-46eb-832a-1f67f981d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991733610292715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsa\\miniconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\katsa\\miniconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    BENIGN       0.99      1.00      0.99    227311\n",
      "                       Bot       0.95      0.38      0.54       199\n",
      "                      DDoS       1.00      1.00      1.00     12663\n",
      "             DoS GoldenEye       0.95      0.98      0.96      1015\n",
      "                  DoS Hulk       0.99      0.94      0.97     23232\n",
      "          DoS Slowhttptest       0.88      0.97      0.93       535\n",
      "             DoS slowloris       0.99      0.89      0.93       588\n",
      "               FTP-Patator       0.99      1.00      0.99       772\n",
      "                Heartbleed       0.00      0.00      0.00         3\n",
      "              Infiltration       0.00      0.00      0.00         3\n",
      "                  PortScan       0.99      0.99      0.99     15962\n",
      "               SSH-Patator       0.90      0.97      0.93       578\n",
      "  Web Attack � Brute Force       0.80      0.06      0.11       142\n",
      "Web Attack � Sql Injection       0.00      0.00      0.00         1\n",
      "          Web Attack � XSS       0.00      0.00      0.00        70\n",
      "\n",
      "                  accuracy                           0.99    283074\n",
      "                 macro avg       0.70      0.61      0.62    283074\n",
      "              weighted avg       0.99      0.99      0.99    283074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katsa\\miniconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "predictions = pipe.predict(X_test.to_numpy())\n",
    "print(metrics.accuracy_score(y_test.to_numpy(), predictions))\n",
    "print(metrics.classification_report(y_test.to_numpy(), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d1a8cc-8a56-4e3d-8a85-a061a42277bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(pipe, \"MLPmodel\")\n",
    "joblib.dump(pipe[1], \"scaler\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
